I conceptualized and developed an innovative application designed to predict user speech by analyzing lip movements. The initial phase involved the meticulous creation of a dataset through manual video recordings, laying the foundation for the subsequent development stages. I implemented a sophisticated VGG-16+LSTM model to effectively predict and interpret the intricate nuances of lip movements. Remarkably, the model yielded an accuracy rate of 44%, positioning it as the second-highest in its domain when compared to prior works. Recognizing the uniqueness and potential impact of this endeavor, I took the initiative to file a design patent for the project. Subsequently, I successfully navigated the approval process with the Government of India, solidifying the project's intellectual property and contributing to its recognition as a pioneering innovation in the field of lip movement analysis and speech prediction.
